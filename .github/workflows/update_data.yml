name: Update Trump Data (Factba.se Source)
on:
  schedule:
    - cron: '*/30 * * * *' # Körs var 30:e minut
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Dependencies
        run: pip install beautifulsoup4 requests

      - name: Scrape Aggregator
        run: |
          cat <<EOF > analyzer.py
          import requests
          import json
          import datetime
          import random
          import re
          from bs4 import BeautifulSoup

          # Målet: Factba.se's specifika sida för Truth Social
          url = "https://factba.se/topic/truth-social"
          
          post_count = 0
          status = "simulated" # Default om det skiter sig
          fetched_success = False
          
          print(f"Försöker hämta från biblioteket: {url}")

          try:
              # Vi maskerar oss som en vanlig Chrome-användare
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
              }
              
              # Hämta sidan (15 sekunders timeout)
              response = requests.get(url, headers=headers, timeout=15)
              
              if response.status_code == 200:
                  html = response.text
                  soup = BeautifulSoup(html, 'html.parser')
                  
                  # STRATEGI: Leta efter tidsstämplar i texten
                  # Factba.se skriver ofta "14 mins ago" eller "X minutes ago"
                  
                  # Vi letar efter alla textsnuttar som innehåller "ago"
                  # Detta är en "grov" metod men väldigt effektiv
                  all_texts = soup.get_text()
                  
                  # Regex för att hitta "X mins ago" eller "X minutes ago"
                  # Vi letar efter siffror följt av 'min' eller 'minute'
                  matches = re.findall(r'(\d+)\s+(min|minute)', all_texts, re.IGNORECASE)
                  
                  real_count = 0
                  print(f"Hittade {len(matches)} tidsstämplar totalt (minuter). Analyserar...")

                  for match in matches:
                      try:
                          # match[0] är siffran (t.ex. "45")
                          minutes_ago = int(match[0])
                          
                          # Vi bryr oss bara om det var mindre än 60 minuter sedan
                          if minutes_ago < 60:
                              real_count += 1
                              print(f" -> Hittade ett färskt inlägg: {minutes_ago} minuter gammalt.")
                      except:
                          continue

                  # Om vi hittade några matches, eller om sidan laddades korrekt men var tom på "mins ago"
                  # (vilket betyder att inget skrivits senaste timmen), så räknas det som SUCCESS.
                  
                  post_count = real_count
                  status = "live"
                  fetched_success = True
                  print(f"SUCCESS: Hittade {real_count} inlägg < 1 timme.")
                  
              else:
                  print(f"Kunde inte nå Factba.se. Status: {response.status_code}")

          except Exception as e:
              print(f"Fel vid skrapning: {e}")

          # --- SÄKERHETSNÄT (SIMULERING) ---
          if not fetched_success:
              print("Kör simulering (Factba.se misslyckades).")
              status = "estimated"
              
              # Din snygga sannolikhetsmodell
              roll = random.randint(0, 100)
              if roll < 65: post_count = 0
              elif roll < 90: post_count = random.randint(1, 2)
              else: post_count = random.randint(3, 6)

          # Spara data
          output = {
              "postCount": post_count,
              "status": status,
              "source": "Factba.se Aggregator",
              "lastUpdated": datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          }

          with open('data.json', 'w') as f:
              json.dump(output, f)
          EOF

          python analyzer.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "action@github.com"
          git add data.json
          git commit -m "Factba.se Update" || exit 0
          git push
