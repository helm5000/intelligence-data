name: Update Trump Data
on:
  schedule:
    - cron: '*/30 * * * *' # Körs var 30:e minut
  workflow_dispatch: # Manuell start

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install CloudScraper
        run: |
          pip install cloudscraper beautifulsoup4

      - name: Run Scraper Script
        run: |
          # Vi skapar ett Python-script direkt här i YAML-filen för att slippa ladda upp fler filer
          cat <<EOF > scraper.py
          import cloudscraper
          import json
          import random
          from datetime import datetime
          from bs4 import BeautifulSoup

          # URL till profilen (vi skrapar profilen istället för RSS då den är oftare öppen)
          url = "https://truthsocial.com/@realDonaldTrump"

          try:
              # Skapa en scraper som lurar Cloudflare
              scraper = cloudscraper.create_scraper(browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False})
              html = scraper.get(url).text
              
              # Använd BeautifulSoup för att räkna inlägg
              soup = BeautifulSoup(html, 'html.parser')
              
              # Vi letar efter antalet "cards" eller artiklar. 
              # Truth Socials struktur ändras ibland, så vi räknar förekomsten av inläggs-länkar
              # Detta är en grov men effektiv metod
              post_count = html.count('data-testid="status-link"')
              
              # Om vi inte hittar den specifika taggen, försök räkna 'article' taggar
              if post_count == 0:
                  post_count = len(soup.find_all('article'))

              if post_count > 0:
                  status = "live"
                  method = "CloudScraper (Python)"
                  print(f"SUCCESS: Hittade {post_count} inlägg via CloudScraper.")
              else:
                  raise Exception("Inga inlägg hittades (troligen blockad eller ändrad layout).")

          except Exception as e:
              print(f"BLOCKERAD: {e}")
              # Fallback-logik om även CloudScraper misslyckas
              post_count = random.randint(5, 14)
              status = "simulated"
              method = "Simulation (Blocked)"

          # Spara till JSON
          data = {
              "postCount": post_count,
              "status": status,
              "method": method,
              "lastUpdated": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          }

          with open('data.json', 'w') as f:
              json.dump(data, f)
          EOF

          # Kör scriptet vi nyss skapade
          python scraper.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "action@github.com"
          git add data.json
          git commit -m "Python Intelligence Update" || exit 0
          git push
