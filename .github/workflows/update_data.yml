name: Update Trump Data
on:
  schedule:
    - cron: '*/30 * * * *' # Körs var 30:e minut
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Fetch and Analyze Real Time Data
        run: |
          cat <<EOF > analyzer.py
          import urllib.request
          import json
          import datetime
          import random
          import sys
          from xml.dom import minidom
          import ssl

          # Vi stänger av SSL-verifiering för att undvika handskaknings-problem med vissa proxys
          ssl._create_default_https_context = ssl._create_unverified_context

          # NY STRATEGI: RSSHub
          # Detta är en specialist-tjänst för sociala medier
          rss_url = "https://rsshub.app/truthsocial/account/realDonaldTrump"

          post_count_last_hour = 0
          status = "estimated"
          fetched_success = False

          now = datetime.datetime.utcnow()
          print(f"Nuvarande tid (UTC): {now}")

          try:
              print(f"Testar RSSHub: {rss_url} ...")
              
              # Vi maskerar oss som en vanlig läsare
              req = urllib.request.Request(
                  rss_url, 
                  headers={
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                  }
              )
              
              # 30 sekunders timeout
              response = urllib.request.urlopen(req, timeout=30)
              rss_content = response.read()
              
              # Försök parsa XML
              dom = minidom.parseString(rss_content)
              items = dom.getElementsByTagName('item')
              
              real_count = 0
              print(f"Hittade {len(items)} inlägg totalt i flödet.")

              for item in items:
                  try:
                      # RSSHub använder oftast standard pubDate
                      pub_date_str = item.getElementsByTagName('pubDate')[0].firstChild.data
                      # Exempel: "Mon, 09 Feb 2026 15:00:00 GMT"
                      # Vi försöker parsa det
                      try:
                          pub_date = datetime.datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                      except:
                          pub_date = datetime.datetime.strptime(pub_date_str[:25], "%a, %d %b %Y %H:%M:%S")

                      # Ta bort tidszon-info för att jämföra med UTC now
                      pub_date = pub_date.replace(tzinfo=None)

                      diff = now - pub_date
                      diff_minutes = diff.total_seconds() / 60
                      
                      print(f"Inlägg: {pub_date} ({int(diff_minutes)} min sedan)")

                      if diff_minutes < 60:
                          real_count += 1
                  except Exception as e:
                      print(f"Kunde inte läsa datum på ett inlägg: {e}")
                      continue

              post_count_last_hour = real_count
              status = "live"
              fetched_success = True
              print(f"SUCCESS: Hittade {real_count} inlägg senaste timmen.")

          except Exception as e:
              print(f"RSSHub misslyckades: {e}")
              # Om vi får 403 Forbidden eller liknande så vet vi att även RSSHub är blockad

          # --- FALLBACK SIMULERING (Om RSSHub är blockad) ---
          if not fetched_success:
              print("Kör simulering (Blockerad av Truth Social).")
              status = "estimated"
              # Din snygga viktade slump: 70% chans för tystnad
              roll = random.randint(0, 100)
              if roll < 70: post_count_last_hour = 0
              elif roll < 90: post_count_last_hour = 1
              else: post_count_last_hour = random.randint(2, 5)

          # Spara data
          output = {
              "postCount": post_count_last_hour,
              "status": status,
              "lastUpdated": datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          }

          with open('data.json', 'w') as f:
              json.dump(output, f)
          EOF

          python analyzer.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "action@github.com"
          git add data.json
          git commit -m "RSSHub Analysis" || exit 0
          git push
