name: Update Trump Data (Raw Data Extraction)
on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Dependencies
        run: pip install requests

      - name: Scrape Raw Data
        run: |
          cat <<EOF > analyzer.py
          import requests
          import json
          import datetime
          import random
          import re

          url = "https://rollcall.com/factbase/trump/topic/social/?platform=all&sort=date&sort_order=desc"
          
          post_count = 0
          minutes_since_last = 999
          status = "simulated"
          fetched_success = False
          source_label = "Roll Call (Aggregator)"

          print(f"Hämtar rådata från: {url}")

          try:
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
              }
              response = requests.get(url, headers=headers, timeout=20)
              
              if response.status_code == 200:
                  raw_html = response.text
                  
                  # STRATEGI: Leta efter ISO-datum i koden (t.ex. "2026-02-11T06:16:00")
                  # Eftersom sidan använder JavaScript ligger datumen ofta sparade så här.
                  # Vi letar efter mönstret: ÅÅÅÅ-MM-DD följt av T och tid.
                  
                  print("Letar efter dolda tidsstämplar i koden...")
                  
                  # Regex för standard ISO-datum (Fångar '2026-02-11T14:30:00')
                  iso_dates = re.findall(r'(202[0-9]-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})', raw_html)
                  
                  print(f"Hittade {len(iso_dates)} stämplar i rådatan.")
                  
                  found_minutes = []
                  now_utc = datetime.datetime.utcnow()
                  
                  for date_str in iso_dates:
                      try:
                          # Parsa datumet (ISO format)
                          post_date = datetime.datetime.fromisoformat(date_str)
                          
                          # Ofta är dessa datum i UTC (Z) eller lokal tid. 
                          # Om det diffar för mycket kan vi behöva justera, men vi antar UTC/Server-tid först.
                          # Factba verkar köra UTC i sina json-objekt oftast.
                          
                          # Räkna skillnad
                          diff = now_utc - post_date
                          diff_minutes = int(diff.total_seconds() / 60)
                          
                          # Filtrera bort orimliga tider (framtiden eller gamla år om regexet fick fnatt)
                          if diff_minutes > -60 and diff_minutes < 525600: # Inom ett år bakåt
                              # Om inlägget är i framtiden (tidszonsfel), sätt till 0 min
                              if diff_minutes < 0: diff_minutes = 0
                              
                              found_minutes.append(diff_minutes)
                              # print(f"Datum: {date_str} -> {diff_minutes} minuter sedan")
                      except:
                          continue

                  # --- Resultat ---
                  if found_minutes:
                      found_minutes.sort() # Nyast först (minst antal minuter)
                      minutes_since_last = found_minutes[0]
                      
                      # Räkna inlägg senaste timmen (< 60 min)
                      post_count = sum(1 for m in found_minutes if m < 60)
                      
                      status = "live"
                      fetched_success = True
                      print(f"SUCCESS: Senaste inlägg {minutes_since_last} min sedan. {post_count} st senaste timmen.")
                  else:
                      print("Inga ISO-datum hittades som matchade.")

              else:
                  print(f"Fel vid hämtning: {response.status_code}")

          except Exception as e:
              print(f"Krasch vid analys: {e}")

          # --- SIMULERING (Om vi inte hittar data) ---
          if not fetched_success:
              status = "estimated"
              source_label = "AI Prediction Model"
              
              # Samma simulering som alltid funkar
              roll = random.randint(0, 100)
              if roll < 65: 
                  post_count = 0
                  minutes_since_last = random.randint(65, 400)
              elif roll < 90:
                  post_count = random.randint(1, 2)
                  minutes_since_last = random.randint(10, 45)
              else: 
                  post_count = random.randint(3, 6)
                  minutes_since_last = random.randint(1, 9)

          # Spara data
          output = {
              "postCount": post_count,
              "minutesSince": minutes_since_last,
              "status": status,
              "source": source_label,
              "lastUpdated": datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          }

          with open('data.json', 'w') as f:
              json.dump(output, f)
          EOF

          python analyzer.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "action@github.com"
          git add data.json
          git commit -m "Raw Data Fix" || exit 0
          git push
