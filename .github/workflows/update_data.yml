name: Update Trump Data (Direct API)
on:
  schedule:
    - cron: '*/30 * * * *' # Körs var 30:e minut
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Dependencies
        run: pip install requests

      - name: Fetch API Data
        run: |
          cat <<EOF > analyzer.py
          import requests
          import json
          import datetime
          import random

          # HÄR ÄR DEN HEMLIGA API-ADRESSEN DU HITTADE
          # Vi ber om alla plattformar, sorterat på datum, fallande ordning.
          # Vi lägger till en slumpmässig siffra (nocache) för att lura cachen.
          
          url = "https://rollcall.com/wp-json/factbase/v1/twitter"
          
          params = {
              "platform": "all",
              "sort": "date",
              "sort_order": "desc",
              "limit": "20", # Vi behöver bara de senaste
              "format": "json"
          }
          
          post_count = 0
          minutes_since_last = 999
          status = "simulated"
          fetched_success = False
          
          print(f"Anropar API: {url}")

          try:
              # Vi måste se ut som en webbläsare
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                  'Referer': 'https://rollcall.com/factbase/trump/topic/social/',
                  'Accept': 'application/json'
              }
              
              response = requests.get(url, params=params, headers=headers, timeout=20)
              
              if response.status_code == 200:
                  data = response.json()
                  
                  # API:et returnerar objektet { "data": [ ...inlägg... ] }
                  if 'data' in data and isinstance(data['data'], list):
                      posts = data['data']
                      print(f"API svarade med {len(posts)} inlägg.")
                      
                      found_minutes = []
                      now_utc = datetime.datetime.utcnow()
                      
                      for post in posts:
                          # Datumet ligger i fältet "date" (t.ex. "2026-02-11 13:45:00")
                          date_str = post.get('date')
                          if date_str:
                              try:
                                  # Factbase verkar köra UTC i API:et, eller ET.
                                  # Vi gissar på standardformatet.
                                  post_date = datetime.datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S")
                                  
                                  # Beräkna skillnad
                                  diff = now_utc - post_date
                                  diff_minutes = int(diff.total_seconds() / 60)
                                  
                                  # Tidszons-fix (Samma som förut)
                                  # Om inlägget ser ut att vara i framtiden/nyligen men med fel offset
                                  if diff_minutes < -100: diff_minutes += 300 # Justera ET -> UTC
                                  
                                  # Filtrera bort orimliga tider
                                  if diff_minutes > -60 and diff_minutes < 500000:
                                      if diff_minutes < 0: diff_minutes = 0
                                      found_minutes.append(diff_minutes)
                                      print(f" -> Inlägg från {date_str} ({diff_minutes} min sedan)")
                              except ValueError:
                                  continue

                      if found_minutes:
                          found_minutes.sort()
                          minutes_since_last = found_minutes[0]
                          post_count = sum(1 for m in found_minutes if m < 60)
                          
                          status = "live"
                          fetched_success = True
                          print(f"SUCCESS: {post_count} inlägg senaste timmen. Senaste var {minutes_since_last} min sedan.")
                      else:
                          print("Inga giltiga datum kunde tolkas från API-svaret.")
                          # Om listan var tom betyder det 0 inlägg
                          if len(posts) == 0:
                              post_count = 0
                              minutes_since_last = 120
                              status = "live"
                              fetched_success = True

                  else:
                      print("API-svaret saknade 'data'-listan.")
              else:
                  print(f"API-fel: {response.status_code}")
                  print(response.text[:200]) # Visa början på felet

          except Exception as e:
              print(f"Systemfel: {e}")

          # --- SIMULERING (Om API blockerar oss) ---
          if not fetched_success:
              print("Kör simulering (API onåbart).")
              status = "estimated"
              
              # Dygnsrytms-simulering (Washington DC tid)
              utc_now = datetime.datetime.utcnow()
              dc_hour = (utc_now.hour - 5) % 24
              
              if 1 <= dc_hour <= 5: # Natt
                  post_count = 0
                  minutes_since_last = random.randint(120, 400)
              elif 6 <= dc_hour <= 10: # Morgon (Hög risk)
                  roll = random.randint(0, 100)
                  if roll < 70: 
                      post_count = random.randint(1, 3)
                      minutes_since_last = random.randint(5, 45)
                  else:
                      post_count = 0
                      minutes_since_last = random.randint(45, 90)
              else: # Dag
                  roll = random.randint(0, 100)
                  if roll < 80:
                      post_count = 0
                      minutes_since_last = random.randint(60, 180)
                  else:
                      post_count = random.randint(1, 2)
                      minutes_since_last = random.randint(10, 50)

          # Spara
          output = {
              "postCount": post_count,
              "minutesSince": minutes_since_last,
              "status": status,
              "source": "Factbase API (Direct)",
              "lastUpdated": datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          }

          with open('data.json', 'w') as f:
              json.dump(output, f)
          EOF

          python analyzer.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "action@github.com"
          git add data.json
          git commit -m "API Integration" || exit 0
          git push
