name: Update Trump Data (With Timestamps)
on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Dependencies
        run: pip install requests beautifulsoup4

      - name: Scrape & Calculate Time
        run: |
          cat <<EOF > analyzer.py
          import requests
          import json
          import datetime
          import random
          import re
          from bs4 import BeautifulSoup

          url = "https://rollcall.com/factbase/trump/topic/social/?platform=all&sort=date&sort_order=desc"
          
          post_count = 0
          minutes_since_last = 999 # Default (länge sen)
          status = "simulated"
          fetched_success = False
          source_label = "Roll Call (Aggregator)"

          try:
              headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
              response = requests.get(url, headers=headers, timeout=20)
              
              if response.status_code == 200:
                  html = response.text
                  soup = BeautifulSoup(html, 'html.parser')
                  text_content = soup.get_text()
                  
                  # Hitta alla tidsangivelser (minuter)
                  # Vi letar efter den minsta siffran (det färskaste inlägget)
                  matches = re.findall(r'(\d+)\s*(m|min|mins|minutes?)\s+ago', text_content, re.IGNORECASE)
                  found_minutes = []
                  
                  for match in matches:
                      try:
                          m = int(match[0])
                          found_minutes.append(m)
                      except:
                          continue
                  
                  # Hitta "Just now" = 0 minuter
                  if re.search(r'(just now|seconds? ago)', text_content, re.IGNORECASE):
                      found_minutes.append(0)

                  # Om vi hittade några tider
                  if found_minutes:
                      found_minutes.sort() # Sortera lägst först
                      minutes_since_last = found_minutes[0]
                      
                      # Räkna hur många som är under 60 min (för indexet)
                      post_count = sum(1 for m in found_minutes if m < 60)
                      
                      status = "live"
                      fetched_success = True
                      print(f"SUCCESS: Senaste inlägg {minutes_since_last} min sedan. {post_count} st senaste timmen.")
                  else:
                      # Om sidan funkar men inga tider hittades (troligen > 1h sen)
                      minutes_since_last = 65 # Sätt till strax över en timme
                      post_count = 0
                      status = "live"
                      fetched_success = True

          except Exception as e:
              print(f"Fel: {e}")

          # --- SIMULERING (Om live misslyckas) ---
          if not fetched_success:
              status = "estimated"
              source_label = "AI Prediction Model"
              
              # Logik: Om han sover (0 inlägg), så var det länge sen sist.
              # Om han är aktiv, var det nyligen.
              roll = random.randint(0, 100)
              
              if roll < 65: 
                  # Lugnt läge
                  post_count = 0
                  minutes_since_last = random.randint(65, 400) # 1h - 6h sen
              elif roll < 90:
                  # Normalt läge
                  post_count = random.randint(1, 2)
                  minutes_since_last = random.randint(10, 45)
              else: 
                  # Kaos läge
                  post_count = random.randint(3, 6)
                  minutes_since_last = random.randint(1, 9)

          # Spara data
          output = {
              "postCount": post_count,
              "minutesSince": minutes_since_last,
              "status": status,
              "source": source_label,
              "lastUpdated": datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
          }

          with open('data.json', 'w') as f:
              json.dump(output, f)
          EOF

          python analyzer.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions"
          git config user.email "action@github.com"
          git add data.json
          git commit -m "Timestamp Update" || exit 0
          git push
